{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T14:37:59.056674Z",
     "iopub.status.busy": "2021-01-11T14:37:59.056241Z",
     "iopub.status.idle": "2021-01-11T14:38:02.220365Z",
     "shell.execute_reply": "2021-01-11T14:38:02.220770Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T14:38:02.223317Z",
     "iopub.status.busy": "2021-01-11T14:38:02.222964Z",
     "iopub.status.idle": "2021-01-11T14:38:02.224598Z",
     "shell.execute_reply": "2021-01-11T14:38:02.224249Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_files = glob.glob(\"txt_sentoken/neg/*.txt\")\n",
    "pos_files = glob.glob(\"txt_sentoken/pos/*.txt\")\n",
    "files = neg_files + pos_files\n",
    "vocab = {}\n",
    "index = 0\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        raw_txt = f.read()\n",
    "    txt_arr = raw_txt.split()\n",
    "    for token in txt_arr:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "            \n",
    "pickle.dump(vocab, open(\"vocab.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate word count feature vectors for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T14:38:02.228124Z",
     "iopub.status.busy": "2021-01-11T14:38:02.227760Z",
     "iopub.status.idle": "2021-01-11T14:38:02.228458Z",
     "shell.execute_reply": "2021-01-11T14:38:02.228781Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "n = len(files)\n",
    "n_neg = len(neg_files)\n",
    "n_pos = len(pos_files)\n",
    "\n",
    "X = np.zeros((n, vocab_size), dtype=np.int8)\n",
    "y = np.concatenate((np.repeat(0, n_neg), np.repeat(1, n_pos))).astype(np.int8)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    with open(file) as f:\n",
    "        raw_txt = f.read()\n",
    "    txt_arr = raw_txt.split()\n",
    "    for token in txt_arr:\n",
    "        X[i, vocab[token]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50920 words out of 50920 words have above 0.000000 instances in each document on average (1.000).\n"
     ]
    }
   ],
   "source": [
    "feature_means = np.mean(X, axis = 0)\n",
    "vocab_size = len(feature_means)\n",
    "\n",
    "threshold = 0.0\n",
    "above_idx = feature_means > threshold\n",
    "num_above = np.sum(above_idx)\n",
    "frac_above = num_above / vocab_size\n",
    "\n",
    "print(\"%d words out of %d words have above %f instances in each document on average (%0.3f).\" % (num_above, vocab_size, threshold, frac_above))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, above_idx]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=400)\n",
    "\n",
    "pickle.dump(X_train, open(\"X_train.pkl\", \"wb\"))\n",
    "pickle.dump(X_test, open(\"X_test.pkl\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"y_train.pkl\", \"wb\"))\n",
    "pickle.dump(y_test, open(\"y_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=400)\n",
    "\n",
    "pickle.dump(X_train, open(\"X_train.pkl\", \"wb\"))\n",
    "pickle.dump(X_test, open(\"X_test.pkl\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"y_train.pkl\", \"wb\"))\n",
    "pickle.dump(y_test, open(\"y_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T14:38:02.232171Z",
     "iopub.status.busy": "2021-01-11T14:38:02.231797Z",
     "iopub.status.idle": "2021-01-11T14:38:02.855965Z",
     "shell.execute_reply": "2021-01-11T14:38:02.855580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1600\n",
      "Test size: 400\n",
      "Vocabulary size: 50920\n",
      "\n",
      "X_train shape: (1600, 50920)\n",
      "X_test shape: (400, 50920)\n",
      "y_train shape: (1600,)\n",
      "y_test shape: (400,)\n"
     ]
    }
   ],
   "source": [
    "X_train = pickle.load(open(\"X_train.pkl\", \"rb\"))\n",
    "X_test = pickle.load(open(\"X_test.pkl\", \"rb\"))\n",
    "y_train = pickle.load(open(\"y_train.pkl\", \"rb\"))\n",
    "y_test = pickle.load(open(\"y_test.pkl\", \"rb\"))\n",
    "\n",
    "vocab = pickle.load(open(\"vocab.pkl\", \"rb\"))\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Test size:\", len(X_test))\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "print()\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Multinomial Logistic Regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T14:38:02.865171Z",
     "iopub.status.busy": "2021-01-11T14:38:02.863077Z",
     "iopub.status.idle": "2021-01-11T14:38:02.866412Z",
     "shell.execute_reply": "2021-01-11T14:38:02.866744Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultinomialLogisticRegressor():\n",
    "    \n",
    "    def __init__(self, lambda_, batch_size, epochs, lr, verbose):\n",
    "        self.lambda_ = lambda_\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        n, d = X.shape\n",
    "        X_appended = np.concatenate((np.ones((n, 1)), X), axis=1)\n",
    "        if not hasattr(self, 'weights'):\n",
    "            self.weights = np.random.normal(size=d+1)\n",
    "        checkpoint = self.epochs // 10\n",
    "        \n",
    "        losses = []\n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            order = np.random.permutation(n)\n",
    "            num_batch = n // self.batch_size\n",
    "            \n",
    "            for i in range(num_batch):\n",
    "                indices = order[i:min(i + batch_size, n)]\n",
    "                X_batch = X_appended[indices]\n",
    "                y_batch = y[indices]\n",
    "                \n",
    "                self.gradient_step(X_batch, y_batch)\n",
    "                \n",
    "            # Compute training loss.\n",
    "            if verbose and (epoch % checkpoint == 0):\n",
    "                logits = np.dot(X_appended, self.weights)\n",
    "                probs = self.sigmoid(logits)\n",
    "                loss = (-(y * np.log(probs) + (1 - y) * np.log(1 - probs)).sum() + self.lambda_ * np.sum(np.abs(self.weights))) / n\n",
    "                \n",
    "                y_pred = (1 + np.sign(logits)) / 2\n",
    "                train_error = np.mean(np.abs(y - y_pred))\n",
    "                print(\"Epoch %d \\t cross entropy loss: %0.4f train error %0.3f\" % (epoch, loss, train_error))\n",
    "                \n",
    "                losses.append(loss)\n",
    "            \n",
    "                \n",
    "        self.fitted = True\n",
    "        return losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        if not hasattr(self, 'fitted'):\n",
    "            raise NotFittedError(\"This MultinomialLogisticRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")\n",
    "            \n",
    "        n = len(X)\n",
    "        X_appended = np.concatenate((np.ones((n, 1)), X), axis=1)\n",
    "        \n",
    "        return (1 + np.sign(np.dot(X_appended, self.weights))) / 2\n",
    "    \n",
    "    def gradient_step(self, X, y):\n",
    "        \n",
    "        # Use l1 regularization.\n",
    "        \n",
    "        n = len(X)\n",
    "        probs = self.sigmoid(np.dot(X, self.weights))\n",
    "        grad = (np.dot(X.T, (probs - y)) + self.lambda_ * self.weights) / n\n",
    "        self.weights = self.weights - self.lr * grad\n",
    "        \n",
    "    def sigmoid(self, Z):\n",
    "        Z_clipped = np.clip(Z, -10, 10)\n",
    "        return 1 / (1 + np.exp(-Z_clipped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if the code works on a toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T15:46:32.929921Z",
     "iopub.status.busy": "2021-01-11T15:46:32.929571Z",
     "iopub.status.idle": "2021-01-11T15:46:33.145605Z",
     "shell.execute_reply": "2021-01-11T15:46:33.145252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t cross entropy loss: 0.0197 train error 0.001\n",
      "Epoch 10 \t cross entropy loss: 0.0020 train error 0.000\n",
      "Epoch 20 \t cross entropy loss: 0.0010 train error 0.000\n",
      "Epoch 30 \t cross entropy loss: 0.0006 train error 0.000\n",
      "Epoch 40 \t cross entropy loss: 0.0006 train error 0.000\n",
      "Epoch 50 \t cross entropy loss: 0.0005 train error 0.000\n",
      "Epoch 60 \t cross entropy loss: 0.0004 train error 0.000\n",
      "Epoch 70 \t cross entropy loss: 0.0003 train error 0.000\n",
      "Epoch 80 \t cross entropy loss: 0.0003 train error 0.000\n",
      "Epoch 90 \t cross entropy loss: 0.0003 train error 0.000\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "d = 10\n",
    "\n",
    "mu = 3 * np.ones(d)\n",
    "cov = np.eye(d)\n",
    "\n",
    "X_neg = np.random.multivariate_normal(-mu, cov, size = n // 2)\n",
    "y_neg = np.repeat(0, n // 2)\n",
    "X_pos = np.random.multivariate_normal(mu, cov, size = n // 2)\n",
    "y_pos = np.repeat(1, n // 2)\n",
    "\n",
    "X = np.concatenate((X_neg, X_pos))\n",
    "y = np.concatenate((y_neg, y_pos))\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "verbose = True\n",
    "lr = 0.03\n",
    "lambda_ = 0.001\n",
    "\n",
    "mlr = MultinomialLogisticRegressor(lambda_=lambda_, batch_size=batch_size, epochs=epochs, lr=lr, verbose=verbose)\n",
    "mlr.fit(X_tr, y_tr)\n",
    "y_pred = mlr.predict(X_te)\n",
    "\n",
    "test_acc = accuracy_score(y_te, y_pred)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run with better hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T15:46:33.149677Z",
     "iopub.status.busy": "2021-01-11T15:46:33.149334Z",
     "iopub.status.idle": "2021-01-11T15:46:33.228690Z",
     "shell.execute_reply": "2021-01-11T15:46:33.228342Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 300\n",
    "verbose = True\n",
    "lr = 0.03\n",
    "lambda_ = 0\n",
    "\n",
    "mlr = MultinomialLogisticRegressor(lambda_=lambda_, batch_size=batch_size, epochs=epochs, lr=lr, verbose=verbose)\n",
    "\n",
    "# 1. Does the loss monotonically decrease? -> \n",
    "# - yes: increase learning rate until no. Move to 2.\n",
    "# - no: decrease learning rate.\n",
    "# 2. Does the model optimize?\n",
    "# - yes: Move to 3.\n",
    "# - no: Increase epochs.\n",
    "# 3. Is there a lare gap between train acc and val acc?\n",
    "# - yes: increase lambda. Move to 1.\n",
    "# - no: Move to 4.\n",
    "# Is the performance reasonable?\n",
    "# - yes: You're done!\n",
    "# - no: decrease lambda. Move to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t cross entropy loss: 3.5150 train error 0.464\n",
      "Epoch 30 \t cross entropy loss: 2.4097 train error 0.349\n",
      "Epoch 60 \t cross entropy loss: 1.6803 train error 0.274\n",
      "Epoch 90 \t cross entropy loss: 1.1966 train error 0.191\n",
      "Epoch 120 \t cross entropy loss: 0.9178 train error 0.167\n",
      "Epoch 150 \t cross entropy loss: 0.6522 train error 0.117\n",
      "Epoch 180 \t cross entropy loss: 0.4932 train error 0.097\n",
      "Epoch 210 \t cross entropy loss: 0.3963 train error 0.076\n",
      "Epoch 240 \t cross entropy loss: 0.2947 train error 0.054\n",
      "Epoch 270 \t cross entropy loss: 0.2195 train error 0.041\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    losses = mlr.fit(X_train, y_train)\n",
    "    plt.plot(np.arange(len(losses)), losses)\n",
    "except KeyboardInterrupt:\n",
    "    print('Graceful Exit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error:  0.315\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlr.predict(X_test)\n",
    "\n",
    "test_error = np.mean(np.abs(y_test - y_pred))\n",
    "\n",
    "print(\"Test error: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T15:46:33.230962Z",
     "iopub.status.busy": "2021-01-11T15:46:33.230618Z",
     "iopub.status.idle": "2021-01-11T15:46:33.233062Z",
     "shell.execute_reply": "2021-01-11T15:46:33.233332Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(mlr, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
